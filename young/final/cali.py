# íŒŒì¼ëª…: calibrate_affine.py

import cv2
import numpy as np
import math

# ==============================================================================
# [ì„¤ì • 1] ì¹´ë©”ë¼ ë° ROI ì„¤ì • (vision_node.pyì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
# ==============================================================================
CAM_INDEX = 2 # vision_node.pyì˜ self.cap = cv2.VideoCapture(2)ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
CAM_WIDTH = 1280
CAM_HEIGHT = 960

# ROI ì„¤ì • (vision_node.pyì™€ ë™ì¼)
ROI_X = 350
ROI_Y = 130
ROI_W = 440
ROI_H = 350

# HSV ìƒ‰ìƒ ë²”ìœ„ (vision_node.pyì™€ ë™ì¼)
LOWER_GREEN = np.array([35, 30, 30])
UPPER_GREEN = np.array([90, 255, 255])

# ==============================================================================
# [ì„¤ì • 2] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì €ì¥ ë³€ìˆ˜
# ==============================================================================
# 3ìŒì˜ (í”½ì…€, ë¡œë´‡) ì¢Œí‘œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
calibration_data = []

# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì¸¡ì •ìš© ë¡œë´‡ ì¢Œí‘œ (ìˆ˜ë™ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•¨)
# ì‚¬ìš©ìê°€ ì§ì ‘ ë¡œë´‡ ì»¨íŠ¸ë¡¤ëŸ¬ì—ì„œ í™•ì¸í•œ ì‹¤ì œ mm ê°’ì„ ì—¬ê¸°ì— ì…ë ¥í•©ë‹ˆë‹¤.
# P1(ì¢Œìƒ), P2(ìš°ìƒ), P3(ì¢Œí•˜)ì˜ ì‹¤ì œ ë¡œë´‡ ì¢Œí‘œ(Z_pick í‰ë©´ ê¸°ì¤€)
TARGET_ROBOT_POSITIONS = [
    # [X, Y] (mm)
    [ 100.0, 150.0],  # P1: ì¢Œìƒë‹¨ ì˜ì—­ (ì˜ˆì‹œê°’)
    [ 100.0, -150.0], # P2: ìš°ìƒë‹¨ ì˜ì—­ (ì˜ˆì‹œê°’)
    [ 300.0, 150.0]   # P3: ì¢Œí•˜ë‹¨ ì˜ì—­ (ì˜ˆì‹œê°’)
]
# Bias Correctionìš© ì¤‘ì•™ì  (ì¶”ê°€ ì¸¡ì •)
TARGET_BIAS_CENTER = [200.0, 0.0] # P_Center (ì˜ˆì‹œê°’)

# ==============================================================================
# [í•¨ìˆ˜] ì´ˆë¡ìƒ‰ íë¸Œ ì¤‘ì‹¬ ì¢Œí‘œ ì°¾ê¸°
# ==============================================================================
def find_green_cube_center(image):
    # 1. ROI ìë¥´ê¸°
    roi = image[ROI_Y : ROI_Y + ROI_H, ROI_X : ROI_X + ROI_W]
    
    # 2. ì´ë¯¸ì§€ ì²˜ë¦¬
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, LOWER_GREEN, UPPER_GREEN)
    mask = cv2.erode(mask, None, iterations=2)
    mask = cv2.dilate(mask, None, iterations=2)

    # 3. ìœ¤ê³½ì„  ê²€ì¶œ
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        if cv2.contourArea(c) > 2000: # ìµœì†Œ ë©´ì  í•„í„°
            M = cv2.moments(c)
            if M["m00"] != 0:
                # ROI ë‚´ë¶€ í”½ì…€ ì¢Œí‘œ
                cx_local = int(M["m10"] / M["m00"])
                cy_local = int(M["m01"] / M["m00"])
                
                # ì „ì²´ í™”ë©´ ê¸°ì¤€ ì¢Œí‘œë¡œ ë³µì›
                cx_global = cx_local + ROI_X
                cy_global = cy_local + ROI_Y
                
                return (cx_global, cy_global), c # ì¤‘ì‹¬ ì¢Œí‘œì™€ ìœ¤ê³½ì„  ë°˜í™˜
                
    return None, None

# ==============================================================================
# [ë©”ì¸ ë£¨í”„] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í–‰
# ==============================================================================
def run_calibration():
    cap = cv2.VideoCapture(CAM_INDEX)
    if not cap.isOpened():
        cap = cv2.VideoCapture(0)
        
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAM_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_HEIGHT)
    
    print("--- Affine ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë„êµ¬ ì‹¤í–‰ ---")
    print(f"í˜„ì¬ ëª©í‘œ ì¸¡ì • íšŸìˆ˜: 3íšŒ (Affine í–‰ë ¬ìš©) + 1íšŒ (Biasìš©)")
    print("---------------------------------")
    
    current_target_index = 0
    
    while cap.isOpened() and current_target_index < len(TARGET_ROBOT_POSITIONS) + 1:
        ret, frame = cap.read()
        if not ret: continue
        
        # íë¸Œ ì¤‘ì‹¬ ì°¾ê¸°
        center_coords, contour = find_green_cube_center(frame)
        
        # ì‹œê°í™”: ROI ì˜ì—­ í‘œì‹œ
        cv2.rectangle(frame, (ROI_X, ROI_Y), (ROI_X + ROI_W, ROI_Y + ROI_H), (255, 0, 0), 2)
        
        if center_coords is not None:
            gx, gy = center_coords
            
            # íë¸Œ ìœ¤ê³½ì„  ë° ì¤‘ì‹¬ì  í‘œì‹œ
            cv2.drawContours(frame, [contour + np.array([ROI_X, ROI_Y])], 0, (0, 255, 0), 3)
            cv2.circle(frame, (gx, gy), 5, (0, 0, 255), -1)
            
            # í˜„ì¬ ìƒíƒœ í‘œì‹œ
            if current_target_index < len(TARGET_ROBOT_POSITIONS):
                target_pos = TARGET_ROBOT_POSITIONS[current_target_index]
                status_text = f"P{current_target_index+1}: Target X={target_pos[0]:.1f}, Y={target_pos[1]:.1f}"
                hint_text = "ì—”í„°(Pixel) | ìŠ¤í˜ì´ìŠ¤(Robot)"
            else:
                target_pos = TARGET_BIAS_CENTER
                status_text = f"P_Center: Target X={target_pos[0]:.1f}, Y={target_pos[1]:.1f}"
                hint_text = "ì—”í„°(Pixel) | ìŠ¤í˜ì´ìŠ¤(Robot) | ESC(ì™„ë£Œ)"

            cv2.putText(frame, status_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            cv2.putText(frame, hint_text, (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

        else:
            cv2.putText(frame, "Cube NOT FOUND!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        cv2.imshow("Affine Calibration Tool", frame)
        
        # í‚¤ ì…ë ¥ ëŒ€ê¸°
        key = cv2.waitKey(1) & 0xFF
        
        if center_coords is not None:
            # 1. íë¸Œ í”½ì…€ ì¢Œí‘œ ì¸¡ì • (ì—”í„° í‚¤)
            if key == 13: # Enter key
                if len(calibration_data) <= current_target_index:
                    calibration_data.append({'pixel': center_coords, 'robot': None, 'target_robot': target_pos})
                    print(f"âœ… P{current_target_index+1} í”½ì…€ ê¸°ë¡: {center_coords}")
                else:
                    calibration_data[current_target_index]['pixel'] = center_coords
                    print(f"ğŸ”„ P{current_target_index+1} í”½ì…€ ì—…ë°ì´íŠ¸: {center_coords}")

            # 2. ë¡œë´‡ ì¢Œí‘œ ì¸¡ì • (ìŠ¤í˜ì´ìŠ¤ ë°”)
            elif key == 32: # Space bar
                if len(calibration_data) > current_target_index and calibration_data[current_target_index]['pixel'] is not None:
                    # ì‚¬ìš©ì ì…ë ¥: ì‹¤ì œ ë¡œë´‡ ì¢Œí‘œë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥ë°›ìŒ
                    print("\n" + "="*50)
                    print(f"P{current_target_index+1} ({'Center' if current_target_index >= 3 else ''})ì˜ í˜„ì¬ ë¡œë´‡ ì¢Œí‘œë¥¼ ì…ë ¥í•˜ì„¸ìš” (Target: {target_pos})")
                    try:
                        robot_x = float(input("Robot X (mm): "))
                        robot_y = float(input("Robot Y (mm): "))
                        
                        calibration_data[current_target_index]['robot'] = (robot_x, robot_y)
                        print(f"âœ… P{current_target_index+1} ë¡œë´‡ ì¢Œí‘œ ê¸°ë¡: ({robot_x}, {robot_y})")
                        
                        # ë‘ ë°ì´í„°ê°€ ëª¨ë‘ ê¸°ë¡ë˜ë©´ ë‹¤ìŒ ì ìœ¼ë¡œ ì´ë™
                        if calibration_data[current_target_index]['robot'] is not None:
                            current_target_index += 1
                            print("â¡ï¸ ë‹¤ìŒ ì¸¡ì • ì§€ì ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                            print("="*50 + "\n")
                    except ValueError:
                        print("âŒ ìœ íš¨í•œ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”. ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
                else:
                    print("âŒ í”½ì…€ ì¢Œí‘œë¥¼ ë¨¼ì € ì¸¡ì •(Enter)í•´ì•¼ ë¡œë´‡ ì¢Œí‘œë¥¼ ê¸°ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # 3. ì™„ë£Œ ë° ì¢…ë£Œ (ESC í‚¤)
        if key == 27 and current_target_index >= 3: # ESC key
            break

    cap.release()
    cv2.destroyAllWindows()
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ê³„ì‚°
    calculate_and_print_matrix(calibration_data)

# ==============================================================================
# [í•¨ìˆ˜] í–‰ë ¬ ê³„ì‚° ë° ê²°ê³¼ ì¶œë ¥
# ==============================================================================
def calculate_and_print_matrix(data):
    if len(data) < 3:
        print("\nâŒ Affine í–‰ë ¬ ê³„ì‚°ì— í•„ìš”í•œ ìµœì†Œ 3ìŒì˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return

    # Affine í–‰ë ¬ ìƒì„±ì— í•„ìš”í•œ 3ìŒì˜ ë°ì´í„°
    pixel_points = np.array([d['pixel'] for d in data[:3]], dtype=np.float32)
    robot_points = np.array([d['robot'] for d in data[:3]], dtype=np.float32)

    # Affine í–‰ë ¬ ê³„ì‚°
    affine_matrix = cv2.getAffineTransform(pixel_points, robot_points)

    print("\n\n" + "="*50)
    print("âœ¨ ìµœì¢… Affine ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ (2x3 í–‰ë ¬) âœ¨")
    print("="*50)
    
    # vision_node.pyì— ë¶™ì—¬ë„£ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì¶œë ¥
    print("AFFINE_MATRIX = np.array([")
    for row in affine_matrix:
        print(f"    [{row[0]:.6f}, {row[1]:.6f}, {row[2]:.6f}],")
    print("], dtype=np.float32)\n")
    
    # Bias Correction ê°’ ê³„ì‚° (P_Center ë°ì´í„° ì‚¬ìš©)
    if len(data) >= 4:
        center_data = data[3]
        pc_pixel = np.array([center_data['pixel']], dtype=np.float32)
        
        # Affine í–‰ë ¬ì„ ì´ìš©í•´ ì¤‘ì•™ì  ë³€í™˜
        pc_calculated = cv2.transform(pc_pixel[None,:,:], affine_matrix)
        
        target_x, target_y = center_data['target_robot']
        calc_x, calc_y = pc_calculated[0][0]
        
        bias_x = target_x - calc_x
        bias_y = target_y - calc_y
        
        print("="*50)
        print("ğŸ’¡ Bias Correction ì˜¤í”„ì…‹ (ì¤‘ì•™ì  ë³´ì •ê°’) ğŸ’¡")
        print(f"  Target Robot Center (X, Y): ({target_x:.3f}, {target_y:.3f})")
        print(f"  Calculated Center (X, Y):  ({calc_x:.3f}, {calc_y:.3f})")
        print(f"  ROBOT_BIAS_X: {bias_x:.6f}")
        print(f"  ROBOT_BIAS_Y: {bias_y:.6f}")
        print("="*50)
        print("ì´ Bias ê°’ì„ vision_node.pyì— ì¶”ê°€í•˜ì—¬ ìµœì¢… ì˜¤ì°¨ë¥¼ ë³´ì •í•˜ì„¸ìš”.")

if __name__ == "__main__":
    run_calibration()