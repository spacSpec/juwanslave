# íŒŒì¼ëª…: calibrate_affine_integrated_final.py
# Affine ë³€í™˜, Bias Correction, Z-Height ê³ ì • ë° ì™œê³¡ ë³´ì • í†µí•© ë²„ì „

import cv2
import numpy as np
import time
import sys
import tty
import termios
from pymycobot.mycobot320 import MyCobot320 

# ==============================================================================
# [ì„¤ì • 0] ë Œì¦ˆ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê³„ìˆ˜ (ì‚¬ìš©ìë‹˜ì˜ ì‹¤ì œ ê³„ìˆ˜ë¡œ êµì²´í•´ì•¼ í•¨!)
# ==============================================================================
CALIB_MATRIX_K = np.array([
    [1.25038936e+03, 0.00000000e+00, 5.74939770e+02], 
    [0.00000000e+00, 1.26131675e+03, 4.72721799e+02],
    [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]
], dtype=np.float32)

DIST_COEFF_D = np.array([
    [0.04689649, 0.54787717, 0.00547649, -0.0037721, -1.14700805]
], dtype=np.float32)


# ==============================================================================
# [ì„¤ì • 1] ë¡œë´‡ ë° ì¹´ë©”ë¼ ì—°ê²° ì •ë³´
# ==============================================================================
PORT = '/dev/ttyACM0' 
BAUD = 115200
CAM_INDEX = 2 
CAM_WIDTH = 1280
CAM_HEIGHT = 960

# ROI ì„¤ì •
ROI_X = 350
ROI_Y = 130
ROI_W = 440
ROI_H = 350

LOWER_GREEN = np.array([35, 30, 30])
UPPER_GREEN = np.array([90, 255, 255])

# ==============================================================================
# [ì„¤ì • 2] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª©í‘œ ì¢Œí‘œ (Z_pick í‰ë©´ ê¸°ì¤€)
# âš ï¸ ì´ ê°’ë“¤ì„ ì‹¤ì œ ë¡œë´‡ ì¢Œí‘œë¡œ ë°˜ë“œì‹œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
# ==============================================================================
TARGET_ROBOT_POSITIONS = [
    [ 100.0, 150.0],  # P1: ì¢Œìƒë‹¨ ì˜ì—­ 
    [ 100.0, -150.0], # P2: ìš°ìƒë‹¨ ì˜ì—­ 
    [ 300.0, 150.0]   # P3: ì¢Œí•˜ë‹¨ ì˜ì—­ 
]
# ëª©í‘œ ì¢Œí‘œ ì •ì˜ ìˆ˜ì •: [566] -> [X, Y]
TARGET_BIAS_CENTER = [566,315] # P_Center ëª©í‘œ ì¢Œí‘œ ì˜ˆì‹œ

mc = None 

# ==============================================================================
# [ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜]
# ==============================================================================
def getch():
    """ë¦¬ëˆ…ìŠ¤ í„°ë¯¸ë„ìš© í‚¤ ì…ë ¥ í•¨ìˆ˜"""
    fd = sys.stdin.fileno()
    old_settings = termios.tcgetattr(fd)
    try:
        tty.setraw(sys.stdin.fileno())
        ch = sys.stdin.read(1)
    finally:
        termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
    return ch

def get_robot_coordinate_from_api():
    """
    MyCobot320ì—ì„œ ì§ì ‘ X, Y ì¢Œí‘œë¥¼ ì½ì–´ì˜µë‹ˆë‹¤. (ì•ˆì •ì„± í™•ë³´ ë¡œì§ í¬í•¨)
    """
    if mc is None:
        print("âŒ ë¡œë´‡ ì—°ê²° ê°ì²´(mc)ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None, None
        
    try:
        # 1. ì¢Œí‘œë¥¼ ì •í™•íˆ ì½ë„ë¡ ì ì‹œ í˜ì„ ì¤ë‹ˆë‹¤.
        mc.power_on() 
        time.sleep(0.1) 
        
        coords = mc.get_coords()
        
        if coords and len(coords) >= 3:
            robot_x = coords[0]
            robot_y = coords[1]
            
            # 2. ì¢Œí‘œë¥¼ ì½ì€ ì§í›„, ë‹¤ì‹œ ìˆ˜ë™ ì´ë™ì´ ê°€ëŠ¥í•˜ë„ë¡ í˜ì„ í’‰ë‹ˆë‹¤.
            mc.release_all_servos() 
            time.sleep(0.1) 

            print(f"\n--- ğŸ¤– í˜„ì¬ ë¡œë´‡ ì¢Œí‘œ íšë“: X={robot_x:.2f}, Y={robot_y:.2f}, Z={coords[2]:.2f} ---")
            return robot_x, robot_y
        else:
            print("\nâŒ ë¡œë´‡ ì¢Œí‘œ ì½ê¸° ì‹¤íŒ¨ (ë°ì´í„° ë¶ˆì™„ì „). í†µì‹  ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return None, None
            
    except Exception as e:
        print(f"\nâŒ ë¡œë´‡ í†µì‹  ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

def find_green_cube_center(image):
    """íë¸Œì˜ ì¤‘ì‹¬ í”½ì…€ ì¢Œí‘œ (ì „ì²´ í™”ë©´ ê¸°ì¤€)ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    # ì™œê³¡ ë³´ì •ëœ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ROIì—ì„œ ì²˜ë¦¬
    roi = image[ROI_Y : ROI_Y + ROI_H, ROI_X : ROI_X + ROI_W]
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, LOWER_GREEN, UPPER_GREEN)
    mask = cv2.erode(mask, None, iterations=2)
    mask = cv2.dilate(mask, None, iterations=2)
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        if cv2.contourArea(c) > 2000:
            M = cv2.moments(c)
            if M["m00"] != 0:
                cx_local = int(M["m10"] / M["m00"])
                cy_local = int(M["m01"] / M["m00"])
                # ì „ì²´ í™”ë©´ ê¸°ì¤€ ì¢Œí‘œë¡œ ë³€í™˜
                cx_global = cx_local + ROI_X
                cy_global = cy_local + ROI_Y
                return (cx_global, cy_global), c 
                
    return None, None

# ==============================================================================
# [ë©”ì¸ ë£¨í”„] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í–‰
# ==============================================================================
def run_calibration_loop():
    global mc 
    
    cap = cv2.VideoCapture(CAM_INDEX)
    if not cap.isOpened():
        cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAM_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_HEIGHT)
    
    print("\n--- ğŸ“ Affine ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë„êµ¬ ì‹¤í–‰ (Z_pick ê³ ì • í•„ìˆ˜) ---")
    
    calibration_data = []
    current_target_index = 0
    target_pos_list = TARGET_ROBOT_POSITIONS + [TARGET_BIAS_CENTER]
    
    while cap.isOpened() and current_target_index < len(target_pos_list):
        ret, raw_frame = cap.read()
        if not ret: continue
        
        # âš ï¸ [ìˆ˜ì •ëœ ì™œê³¡ ë³´ì • ë¡œì§] raw_frameì„ í´ì„œ frameì— ì €ì¥
        frame = cv2.undistort(raw_frame, CALIB_MATRIX_K, DIST_COEFF_D, None, CALIB_MATRIX_K)
        
        center_coords, contour = find_green_cube_center(frame) # ì™œê³¡ ë³´ì •ëœ frame ì‚¬ìš©
        target_pos = target_pos_list[current_target_index]
        
        # ì‹œê°í™”
        cv2.rectangle(frame, (ROI_X, ROI_Y), (ROI_X + ROI_W, ROI_Y + ROI_H), (255, 0, 0), 2)

        label = "P_Center" if current_target_index >= 3 else f"P{current_target_index+1}"
        status_text = f"[{label}] Target X={target_pos[0]:.1f}, Y={target_pos[1]:.1f}"
        hint_text = "ENTER(Pixel ê¸°ë¡) | SPACE(Robot ê¸°ë¡ & ë‹¤ìŒ) | ESC(ì¢…ë£Œ)"

        if center_coords is not None:
            gx, gy = center_coords
            if contour is not None:
                contour_shift = np.array([ROI_X, ROI_Y])
                cv2.drawContours(frame, [contour + contour_shift], 0, (0, 255, 0), 3)
            cv2.circle(frame, (gx, gy), 5, (0, 0, 255), -1)
        else:
            status_text += " | âŒ íë¸Œë¥¼ ë°°ì¹˜í•˜ì„¸ìš”."
        
        cv2.putText(frame, status_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
        cv2.putText(frame, hint_text, (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
        
        cv2.imshow("Affine Calibration Tool", frame)
        
        key = cv2.waitKey(1) & 0xFF
        
        if center_coords is not None:
            # 1. íë¸Œ í”½ì…€ ì¢Œí‘œ ì¸¡ì • (Enter í‚¤)
            if key == 13: # Enter key
                if len(calibration_data) <= current_target_index:
                    calibration_data.append({'pixel': center_coords, 'robot': None, 'target_robot': target_pos})
                else:
                    calibration_data[current_target_index]['pixel'] = center_coords
                print(f"\nâœ… {label} í”½ì…€ ê¸°ë¡: {center_coords}")

            # 2. ë¡œë´‡ ì¢Œí‘œ ì¸¡ì • (Space bar) - ë¡œë´‡ í†µì‹  í˜¸ì¶œ
            elif key == 32: # Space key
                if len(calibration_data) > current_target_index and calibration_data[current_target_index]['pixel'] is not None:
                    
                    robot_coords = get_robot_coordinate_from_api() 
                    
                    if robot_coords and robot_coords[0] is not None:
                        calibration_data[current_target_index]['robot'] = robot_coords
                        print(f"âœ… {label} ë¡œë´‡ ì¢Œí‘œ ê¸°ë¡: {robot_coords}")
                        
                        # ë‘ ë°ì´í„°ê°€ ëª¨ë‘ ê¸°ë¡ë˜ë©´ ë‹¤ìŒ ì ìœ¼ë¡œ ì´ë™
                        current_target_index += 1
                        print("="*50 + "\nâ¡ï¸ ë‹¤ìŒ ì¸¡ì • ì§€ì ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                    
                else:
                    print("âŒ í”½ì…€ ì¢Œí‘œë¥¼ ë¨¼ì € ì¸¡ì •(Enter)í•´ì•¼ ë¡œë´‡ ì¢Œí‘œë¥¼ ê¸°ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # 3. ì¢…ë£Œ (ESC í‚¤)
        if key == 27: # ESC key
            break

    cap.release()
    cv2.destroyAllWindows()
    
    # ìµœì¢… í–‰ë ¬ ê³„ì‚°
    calculate_and_print_matrix(calibration_data)

# ==============================================================================
# [í•¨ìˆ˜] í–‰ë ¬ ê³„ì‚° ë° ê²°ê³¼ ì¶œë ¥
# ==============================================================================
def calculate_and_print_matrix(data):
    affine_data = [d for d in data[:3] if d.get('pixel') and d.get('robot')]
    
    if len(affine_data) < 3:
        print("\nâŒ Affine í–‰ë ¬ ê³„ì‚°ì— í•„ìš”í•œ ìµœì†Œ 3ìŒì˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    pixel_points = np.array([d['pixel'] for d in affine_data], dtype=np.float32)
    robot_points = np.array([d['robot'] for d in affine_data], dtype=np.float32)

    affine_matrix = cv2.getAffineTransform(pixel_points, robot_points)

    print("\n\n" + "="*50)
    print("âœ¨ ìµœì¢… Affine ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ (2x3 í–‰ë ¬) âœ¨")
    print(" vision_node.pyì˜ AFFINE_MATRIXì— ì´ ê°’ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
    print("="*50)
    
    print("AFFINE_MATRIX = np.array([")
    for row in affine_matrix:
        print(f"    [{row[0]:.6f}, {row[1]:.6f}, {row[2]:.6f}],")
    print("], dtype=np.float32)\n")
    
    # Bias Correction ê°’ ê³„ì‚° (P_Center ë°ì´í„° ì‚¬ìš©)
    if len(data) >= 4 and data[3].get('pixel') and data[3].get('robot'):
        center_data = data[3]
        pc_pixel = np.array([center_data['pixel']], dtype=np.float32)
        
        # Affine í–‰ë ¬ì„ ì´ìš©í•´ ì¤‘ì•™ì  ë³€í™˜
        pc_calculated = cv2.transform(pc_pixel[None,:,:], affine_matrix)
        
        target_x, target_y = center_data['target_robot']
        calc_x, calc_y = pc_calculated[0][0]
        
        bias_x = target_x - calc_x
        bias_y = target_y - calc_y
        
        print("="*50)
        print("ğŸ’¡ Bias Correction ì˜¤í”„ì…‹ (ì¤‘ì•™ì  ë³´ì •ê°’) ğŸ’¡")
        print(" vision_node.pyì˜ ROBOT_BIAS_X/Yì— ì´ ê°’ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
        print(f"  Target Robot Center (X, Y): ({target_x:.3f}, {target_y:.3f})")
        print(f"  Calculated Center (X, Y):  ({calc_x:.3f}, {calc_y:.3f})")
        print(f"  ROBOT_BIAS_X: {bias_x:.6f}")
        print(f"  ROBOT_BIAS_Y: {bias_y:.6f}")
        print("="*50)

# ==============================================================================
# [ë©”ì¸ ì‹¤í–‰] ë¡œë´‡ ì—°ê²° ë° ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘
# ==============================================================================
def main():
    global mc 
    try:
        print(f"ğŸ”Œ ë¡œë´‡ ì—°ê²° ì‹œë„ ì¤‘... ({PORT})")
        mc = MyCobot320(PORT, BAUD)
        mc.power_on()
        time.sleep(1)
        mc.release_all_servos()
        print("âœ… ë¡œë´‡ ì—°ê²° ì„±ê³µ! ì¹´ë©”ë¼ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ë¡œë´‡ ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit()

    try:
        run_calibration_loop()
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ ì¢…ë£Œ.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if mc:
            mc.power_on()
            print("ë¡œë´‡ì— ë‹¤ì‹œ í˜ì„ ì£¼ì–´ ìì„¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
            time.sleep(0.5)

if __name__ == "__main__":
    main()