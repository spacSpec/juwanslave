import os
import glob
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights
from scipy.spatial.distance import mahalanobis
from scipy.linalg import inv
from sklearn.metrics import roc_auc_score

# ----------------------------------------------------
# 1. ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# ----------------------------------------------------

# ë°ì´í„°ì…‹ì˜ ìµœìƒìœ„ ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ í™•ì¸ í•„ìˆ˜)
# ì „ì²˜ë¦¬(Alignment)ê°€ ì™„ë£Œëœ ì´ë¯¸ì§€ë“¤ì´ ë“¤ì–´ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
DATASET_ROOT = "/home/young/final_ws/datasets/cube" 
TRAIN_GOOD_DIR = os.path.join(DATASET_ROOT, "train", "good")
TEST_DIR = os.path.join(DATASET_ROOT, "test")

# PaDiM ëª¨ë¸ ê²°ê³¼ ì €ì¥ ê²½ë¡œ
MODEL_OUTPUT_DIR = "padim_weights/cube"
os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)

# PaDiM ì„¤ì •
NUM_RANDOM_CHANNELS = 300 # 1500ì€ ë©”ëª¨ë¦¬ê°€ í„°ì§ˆ ìˆ˜ ìˆì–´ 550 ì •ë„ë¡œ ì¤„ì´ëŠ” ê²½ìš°ë„ ìˆìŒ (RAM ì¶©ë¶„í•˜ë©´ 1500 ìœ ì§€)
COV_IDENTITY_FACTOR = 0.01 
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# [í•µì‹¬ ìˆ˜ì • ì‚¬í•­] ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# CenterCropì„ ì œê±°í•˜ê³  (224, 224)ë¡œ ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.
# ì´ë¯¸ íƒ€ì´íŠ¸í•˜ê²Œ ì˜ë¦°(Alignment) ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë¯€ë¡œ, ì˜ë¼ë‚´ì§€ ì•Šê³  ì°Œê·¸ëŸ¬ëœ¨ë ¤ì„œë¼ë„ ì „ì²´ë¥¼ ë‹¤ ë´ì•¼ í•©ë‹ˆë‹¤.
TRANSFORM = transforms.Compose([
    transforms.Resize((224, 224), Image.LANCZOS), # ê°€ë¡œì„¸ë¡œ 224ë¡œ ê°•ì œ ê³ ì •
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ----------------------------------------------------
# 2. ResNet íŠ¹ì§• ì¶”ì¶œê¸° ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ----------------------------------------------------

def get_resnet_backbone():
    """Wide ResNet50-2 ëª¨ë¸ì„ ë¡œë“œí•˜ê³  íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ Hookì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    # weights ë§¤ê°œë³€ìˆ˜ ì‚¬ìš© (ìµœì‹  PyTorch ë²„ì „ ëŒ€ì‘)
    model = wide_resnet50_2(weights=Wide_ResNet50_2_Weights.IMAGENET1K_V2)
    
    feature_maps = {}
    def hook_fn(module, input, output, name):
        # Layer 3 íŠ¹ì§• ë§µì€ Layer 2 í¬ê¸°ì— ë§ê²Œ ì—…ìƒ˜í”Œë§ (PaDiM í‘œì¤€)
        if name == 'layer3':
            output = F.interpolate(output, size=(28, 28), mode='bilinear', align_corners=False)
        # Layer 1 íŠ¹ì§• ë§µì€ Layer 2 í¬ê¸°ì— ë§ê²Œ ë‹¤ìš´ìƒ˜í”Œë§ (PaDiM í‘œì¤€)
        elif name == 'layer1':
             output = F.avg_pool2d(output, kernel_size=2)
             
        feature_maps[name] = output

    # Hook ì—°ê²° (Layer 1, 2, 3)
    model.layer1.register_forward_hook(lambda m, i, o: hook_fn(m, i, o, 'layer1'))
    model.layer2.register_forward_hook(lambda m, i, o: hook_fn(m, i, o, 'layer2'))
    model.layer3.register_forward_hook(lambda m, i, o: hook_fn(m, i, o, 'layer3'))
    
    model.fc = torch.nn.Identity()
    model.eval()
    model.to(DEVICE)
    
    return model, feature_maps

def extract_patch_features(model, feature_maps, image_tensor):
    """ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•´ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  íŒ¨ì¹˜ ë‹¨ìœ„ë¡œ í•©ì³ì„œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    with torch.no_grad():
        _ = model(image_tensor.to(DEVICE))
    
    # Layer 1, 2, 3ì˜ íŠ¹ì§• ë§µì„ ì±„ë„ ì°¨ì›ì—ì„œ ì—°ê²°: (1, 1792, 28, 28)
    combined_features = torch.cat([feature_maps['layer1'], feature_maps['layer2'], feature_maps['layer3']], dim=1)
    
    # (B, C, H, W) -> (B, H*W, C) í˜•íƒœë¡œ ë³€í™˜ -> (784, 1792)
    patch_features = combined_features.permute(0, 2, 3, 1).flatten(1, 2).squeeze(0) 
    
    return patch_features.cpu().numpy()

# ----------------------------------------------------
# 3. í•™ìŠµ ë‹¨ê³„ (ë¶„í¬ ëª¨ë¸ë§)
# ----------------------------------------------------

def train_padim_model(model, feature_maps):
    """ì •ìƒ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨ì¹˜ íŠ¹ì§•ì˜ í‰ê· ê³¼ ê³µë¶„ì‚°ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    
    image_files = glob.glob(os.path.join(TRAIN_GOOD_DIR, '*.png')) + \
                  glob.glob(os.path.join(TRAIN_GOOD_DIR, '*.jpg'))
    
    if not image_files:
        print(f"âŒ ì˜¤ë¥˜: '{TRAIN_GOOD_DIR}'ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None

    print(f"\n[Step 1: í•™ìŠµ] ì´ {len(image_files)}ê°œì˜ ì •ìƒ ì´ë¯¸ì§€ë¡œ PaDiM í•™ìŠµ ì‹œì‘.")
    
    all_patch_features = []
    
    for i, file_path in enumerate(image_files):
        try:
            image = Image.open(file_path).convert('RGB')
            tensor = TRANSFORM(image).unsqueeze(0) # ì—¬ê¸°ì„œ Resize((224,224)) ì ìš©ë¨
            
            patch_features = extract_patch_features(model, feature_maps, tensor)
            all_patch_features.append(patch_features)
            
            print(f"   > ì´ë¯¸ì§€ {i+1}/{len(image_files)} ì²˜ë¦¬ ì™„ë£Œ.", end='\r')
        except Exception as e:
            print(f"\n   âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {file_path}, ì˜¤ë¥˜: {e}")
            continue

    if not all_patch_features:
        print("\nâŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨. ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None, None, None

    # ë©”ëª¨ë¦¬ ì£¼ì˜: ì´ë¯¸ì§€ê°€ ë§ìœ¼ë©´ ì—¬ê¸°ì„œ OOM(Out of Memory) ë°œìƒ ê°€ëŠ¥
    all_features_concatenated = np.concatenate(all_patch_features, axis=0)
    total_channels = all_features_concatenated.shape[1] 

    # 1. ëœë¤ ì±„ë„ ì„ íƒ (ì°¨ì› ì¶•ì†Œ)
    # NUM_RANDOM_CHANNELSê°€ ì „ì²´ ì±„ë„ë³´ë‹¤ í¬ë©´ ì „ì²´ ì±„ë„ ì‚¬ìš©
    n_channels = min(NUM_RANDOM_CHANNELS, total_channels)
    random_channels = np.random.choice(total_channels, n_channels, replace=False)
    final_features = all_features_concatenated[:, random_channels]
    
    print(f"\nâœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ. ìµœì¢… íŠ¹ì§• í–‰ë ¬ í˜•íƒœ: {final_features.shape}")

    # 2. í‰ê·  ë²¡í„° (Î¼) ê³„ì‚°
    mean_vector = np.mean(final_features, axis=0)
    
    # 3. ê³µë¶„ì‚° í–‰ë ¬ (Î£) ê³„ì‚°
    cov_matrix = np.cov(final_features, rowvar=False)
    
    # 4. ì •ê·œí™” ë° ì—­í–‰ë ¬ ê³„ì‚°
    identity = np.eye(cov_matrix.shape[0]) * COV_IDENTITY_FACTOR 
    cov_matrix += identity
    inv_cov_matrix = inv(cov_matrix)

    # 5. ì €ì¥
    np.save(os.path.join(MODEL_OUTPUT_DIR, 'mean_vector.npy'), mean_vector)
    np.save(os.path.join(MODEL_OUTPUT_DIR, 'inv_cov_matrix.npy'), inv_cov_matrix)
    np.save(os.path.join(MODEL_OUTPUT_DIR, 'random_channels.npy'), random_channels)
    
    print(f"\nğŸ‰ PaDiM í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ '{MODEL_OUTPUT_DIR}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return mean_vector, inv_cov_matrix, random_channels

# ----------------------------------------------------
# 4. í…ŒìŠ¤íŠ¸ ë‹¨ê³„ (í‰ê°€)
# ----------------------------------------------------

def test_padim_model(model, feature_maps, mean_vector, inv_cov_matrix, random_channels):
    
    all_test_files = []
    all_test_labels = [] # 0: good, 1: anomaly

    if not os.path.exists(TEST_DIR):
        print(f"\nâŒ ì˜¤ë¥˜: í…ŒìŠ¤íŠ¸ í´ë” '{TEST_DIR}'ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # test í´ë” êµ¬ì¡°: test/good, test/defect_type1, ...
    for class_dir in os.listdir(TEST_DIR):
        class_path = os.path.join(TEST_DIR, class_dir)
        if os.path.isdir(class_path):
            # 'good' í´ë”ë©´ ë¼ë²¨ 0, ê·¸ ì™¸(ë¶ˆëŸ‰)ë©´ ë¼ë²¨ 1
            label = 0 if class_dir == 'good' else 1
            files = glob.glob(os.path.join(class_path, '*.png')) + \
                    glob.glob(os.path.join(class_path, '*.jpg'))
            
            all_test_files.extend(files)
            all_test_labels.extend([label] * len(files))

    if not all_test_files:
        print(f"\nâŒ ì˜¤ë¥˜: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n[Step 2: í…ŒìŠ¤íŠ¸] ì´ {len(all_test_files)}ê°œì˜ ì´ë¯¸ì§€ í‰ê°€ ì‹œì‘.")
    
    image_anomaly_scores = []
    
    for i, file_path in enumerate(all_test_files):
        try:
            image = Image.open(file_path).convert('RGB')
            tensor = TRANSFORM(image).unsqueeze(0) # Resize((224,224)) ì ìš©
            
            patch_features_full = extract_patch_features(model, feature_maps, tensor)
            patch_features_reduced = patch_features_full[:, random_channels] 
            
            # ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ ê³„ì‚° (Scipy cdist ì‚¬ìš©í•˜ë©´ ë” ë¹ ë¥´ì§€ë§Œ, ê°€ë…ì„±ì„ ìœ„í•´ ë£¨í”„ ìœ ì§€)
            # ëŒ€ëŸ‰ ì²˜ë¦¬ì‹œì—ëŠ” cdist(patch_features_reduced, [mean_vector], metric='mahalanobis', VI=inv_cov_matrix) ê¶Œì¥
            mahala_distances = []
            for patch_feat in patch_features_reduced:
                dist = mahalanobis(patch_feat, mean_vector, inv_cov_matrix)
                mahala_distances.append(dist)
            
            # [ì‚¬ìš©ì ë¡œì§ ë°˜ì˜] ìƒìœ„ Nê°œ íŒ¨ì¹˜ ê±°ë¦¬ í‰ê·  ê³„ì‚°
            N = 10 
            sorted_distances = np.sort(mahala_distances)[::-1] # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            top_n_distances = sorted_distances[:min(N, len(sorted_distances))]
            image_score = np.mean(top_n_distances)
            
            image_anomaly_scores.append(image_score)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            print(f"   > ì²˜ë¦¬ ì¤‘: {i+1}/{len(all_test_files)} | Score: {image_score:.4f}", end='\r')
            
        except Exception as e:
            print(f"\n   âš ï¸ ì˜¤ë¥˜: {file_path} - {e}")
            image_anomaly_scores.append(0.0)

    # ROC AUC í‰ê°€
    image_anomaly_scores = np.array(image_anomaly_scores)
    all_test_labels = np.array(all_test_labels)

    if len(np.unique(all_test_labels)) > 1:
        image_auc = roc_auc_score(all_test_labels, image_anomaly_scores)
        print(f"\n\n==============================================")
        print(f"âœ¨ Image-level ROC AUC: {image_auc:.4f}")
        print(f"==============================================")
    else:
        print("\n\nâš ï¸ AUC ê³„ì‚° ë¶ˆê°€: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì •ìƒ ë˜ëŠ” ë¶ˆëŸ‰ ì¤‘ í•˜ë‚˜ë§Œ ì¡´ì¬í•©ë‹ˆë‹¤.")

# ----------------------------------------------------
# 5. ì‹¤í–‰
# ----------------------------------------------------

if __name__ == "__main__":
    
    # 1. ëª¨ë¸ ì¤€ë¹„
    model, feature_maps = get_resnet_backbone()
    
    # 2. í•™ìŠµ (ì •ìƒ ë°ì´í„° ë¶„í¬ ëª¨ë¸ë§)
    mean_vec, inv_cov_mat, rand_channels = train_padim_model(model, feature_maps)
    
    # 3. í…ŒìŠ¤íŠ¸ (ì´ìƒ íƒì§€ ì„±ëŠ¥ í‰ê°€)
    if mean_vec is not None:
        test_padim_model(model, feature_maps, mean_vec, inv_cov_mat, rand_channels)