import numpy as np
import cv2
import time
# ğŸš¨ MyCobot ì œì–´ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (pymycobot ê¸°ì¤€)
# pip install pymycobot
from pymycobot.mycobot320 import MyCobot320

# --- 1. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë° ROI ìƒìˆ˜ ì •ì˜ ---
CALIB_MATRIX_K = np.array([
    [1.25038936e+03, 0.00000000e+00, 5.74939770e+02],
    [0.00000000e+00, 1.26131675e+03, 4.72721799e+02],
    [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]
])
DIST_COEFF_D = np.array([
    [0.04689649, 0.54787717, 0.00547649, -0.0037721, -1.14700805]
])

# í”½ì¡´(ROI) ì˜ì—­ ì •ì˜ (í”½ì…€ ì¢Œí‘œ) ë° ì¹´ë©”ë¼ ì¸ë±ìŠ¤
ROI_PIXEL_X_MIN = 250
ROI_PIXEL_Y_MIN = 250
ROI_PIXEL_X_MAX = 750
ROI_PIXEL_Y_MAX = 650
CAMERA_INDEX = 0 

# --- 2. MyCobot ì œì–´ í´ë˜ìŠ¤ (ì‹¤ì œ API í˜¸ì¶œ) ---

class MyCobotController:
    """MyCobot 320 ì œì–´ ë° ì¢Œí‘œ íšë“ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, port, baudrate=115200):
        try:
            # ğŸš¨ ì‚¬ìš©ì í™˜ê²½ì— ë§ëŠ” ì‹œë¦¬ì–¼ í¬íŠ¸ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš” (ì˜ˆ: '/dev/ttyACM0' ë˜ëŠ” 'COM3')
            self.mc = MyCobot320(port, baudrate)
            self.mc.set_color(0, 0, 255) # ì—°ê²° í™•ì¸ìš© (íŒŒë€ìƒ‰)
            print(f"âœ… MyCobot ì—°ê²° ì„±ê³µ: {port}")
        except Exception as e:
            print(f"ğŸš¨ MyCobot ì—°ê²° ì‹¤íŒ¨: {e}")
            self.mc = None

    def release_for_manual(self):
        """ê·¸ë¦¬í¼/í† í¬ í•´ì œ (ìˆ˜ë™ ì œì–´ ê°€ëŠ¥ ìƒíƒœ)"""
        if self.mc:
            # ëª¨ë“  ì„œë³´ëª¨í„° í† í¬ í•´ì œ
            self.mc.release_all_servos() 
            self.mc.set_color(255, 0, 0) # í† í¬ í•´ì œ ì‹œ ë¹¨ê°„ìƒ‰ í‘œì‹œ
            print("ğŸ¤– [MyCobot] ëª¨ë“  ì„œë³´ëª¨í„° í† í¬ í•´ì œ. ë¡œë´‡ì„ ìˆ˜ë™ìœ¼ë¡œ ì›€ì§ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return True
        return False

    def get_current_coords(self):
        """í˜„ì¬ ë¡œë´‡ì˜ TCP ì¢Œí‘œ (X, Y, Z)ë¥¼ ê°€ì ¸ì˜´"""
        if self.mc:
            # get_coords()ëŠ” [X, Y, Z, Rx, Ry, Rz] ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
            coords = self.mc.get_coords()
            if coords:
                # í”½ì•¤í”Œë ˆì´ìŠ¤ëŠ” X, Y ì¢Œí‘œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
                x, y, z = coords[0], coords[1], coords[2]
                self.mc.set_color(0, 255, 0) # ì¢Œí‘œ íšë“ ì‹œ ì´ˆë¡ìƒ‰ í‘œì‹œ
                return (x, y)
        print("ğŸš¨ ë¡œë´‡ ì¢Œí‘œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë¡œë´‡ì´ 'ì œì–´ ëª¨ë“œ'ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None

# --- 3. í•µì‹¬ í•¨ìˆ˜: ì´ˆë¡ìƒ‰ íë¸Œ ê°ì§€ (ì´ì „ ì½”ë“œì™€ ë™ì¼) ---

def detect_green_cube(frame):
    # (ì½”ë“œ ìƒëµ: ì´ˆë¡ìƒ‰ íë¸Œ ê°ì§€ ë° ROI í•„í„°ë§ ë¡œì§)
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    lower_green = np.array([40, 50, 50])
    upper_green = np.array([80, 255, 255])
    mask = cv2.inRange(hsv, lower_green, upper_green)
    mask = cv2.erode(mask, None, iterations=2)
    mask = cv2.dilate(mask, None, iterations=2)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        c = max(contours, key=cv2.contourArea)
        if cv2.contourArea(c) > 500:
            M = cv2.moments(c)
            if M["m00"] != 0:
                center_x = int(M["m10"] / M["m00"])
                center_y = int(M["m01"] / M["m00"])
                if (ROI_PIXEL_X_MIN <= center_x <= ROI_PIXEL_X_MAX) and \
                   (ROI_PIXEL_Y_MIN <= center_y <= ROI_PIXEL_Y_MAX):
                    return (center_x, center_y)
    return None

# --- 4. í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° í•¨ìˆ˜ (ì´ì „ ì½”ë“œì™€ ë™ì¼) ---

def calculate_homography_matrix_ransac(pixel_src_distorted, robot_dst_points):
    """ì œê³µëœ K, Dì™€ í”½ì…€-ë¡œë´‡ ìŒì„ ì‚¬ìš©í•˜ì—¬ H í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if len(pixel_src_distorted) < 4 or len(pixel_src_distorted) != len(robot_dst_points):
        return None
        
    src_distorted_np = np.array(pixel_src_distorted, dtype=np.float32).reshape(-1, 1, 2)
    src_undistorted_np = cv2.undistortPoints(
        src_distorted_np, CALIB_MATRIX_K, DIST_COEFF_D, P=CALIB_MATRIX_K
    )
    src_undistorted = src_undistorted_np.reshape(-1, 2)
    dst_robot = np.float32(robot_dst_points)

    H, mask = cv2.findHomography(
        src_undistorted, dst_robot, method=cv2.RANSAC, reprojectionThreshold=1.0
    )
    
    inlier_ratio = np.sum(mask) / len(mask)
    print(f"\n--- ìµœì¢… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ---")
    print(f"RANSAC Inlier ë¹„ìœ¨: {inlier_ratio*100:.2f}% (ìµœì†Œ 80% ì´ìƒ ê¶Œì¥)")
    
    return H

# --- 5. ìˆ˜ë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë£¨í”„ ---

def manual_calibration_loop(robot_controller):
    cap = cv2.VideoCapture(CAMERA_INDEX)
    if not cap.isOpened():
        print(f"ğŸš¨ ì˜¤ë¥˜: ì¹´ë©”ë¼ ì¸ë±ìŠ¤ {CAMERA_INDEX}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    pixel_src_distorted = []
    robot_dst_points = []
    current_pixel = None
    
    # ë¡œë´‡ ì—°ê²° í™•ì¸
    if not robot_controller.mc:
        print("ğŸš¨ ë¡œë´‡ì´ ì—°ê²°ë˜ì§€ ì•Šì•„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        cap.release()
        cv2.destroyAllWindows()
        return

    print("\n==================================================================")
    print("      ğŸŸ¢ MyCobot ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘")
    print("==================================================================")
    print(" - [Enter] í‚¤: ì´ˆë¡ìƒ‰ íë¸Œ í”½ì…€ ì¢Œí‘œ ì €ì¥ ë° MyCobot 'Release' ëª…ë ¹")
    print(" - [Space] í‚¤: ë¡œë´‡ ìˆ˜ë™ ì´ë™ í›„ í˜„ì¬ ë¡œë´‡ ì¢Œí‘œ 'Get' ë° ì €ì¥")
    print(" - [Q] ë˜ëŠ” [ESC] í‚¤: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¢…ë£Œ ë° H í–‰ë ¬ ê³„ì‚°")
    print("==================================================================")
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            display_frame = frame.copy()
            cv2.rectangle(display_frame, (ROI_PIXEL_X_MIN, ROI_PIXEL_Y_MIN), 
                          (ROI_PIXEL_X_MAX, ROI_PIXEL_Y_MAX), (0, 255, 0), 2)
            
            detected_coords = detect_green_cube(frame)
            current_pixel = detected_coords
            
            if current_pixel:
                cv2.circle(display_frame, current_pixel, 10, (0, 0, 255), -1) 
                cv2.putText(display_frame, f"Pixel: {current_pixel}", (current_pixel[0] + 15, current_pixel[1] - 15), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            
            cv2.putText(display_frame, f"Pairs Collected: {len(pixel_src_distorted)}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.imshow("MyCobot Calibration View - Press ENTER/SPACE/Q", display_frame)

            key = cv2.waitKey(1)
            
            if key == 13:  # Enter í‚¤: í”½ì…€ ì¢Œí‘œ ì €ì¥ ë° ë¡œë´‡ 'Release'
                if current_pixel:
                    pixel_src_distorted.append(current_pixel)
                    print(f"\n--- [Enter] 1. í”½ì…€ ì¢Œí‘œ ì €ì¥: {current_pixel} (ìŒ ê°œìˆ˜: {len(pixel_src_distorted)})")
                    robot_controller.release_for_manual()
                else:
                    print("ğŸš¨ ë¬¼ì²´ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ROI ë°–ì— ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                    
            elif key == 32:  # Spacebar í‚¤: ë¡œë´‡ ì¢Œí‘œ ì €ì¥
                if len(pixel_src_distorted) > len(robot_dst_points):
                    robot_coords = robot_controller.get_current_coords()
                    
                    if robot_coords:
                        robot_dst_points.append(robot_coords[:2]) # X, Yë§Œ ì €ì¥
                        print(f"--- [Space] 2. ë¡œë´‡ ì¢Œí‘œ ì €ì¥: {robot_coords[:2]} (ìŒ ê°œìˆ˜: {len(robot_dst_points)})")
                        
                        if len(pixel_src_distorted) != len(robot_dst_points):
                            print("ğŸš¨ ê²½ê³ : í”½ì…€/ë¡œë´‡ ì¢Œí‘œ ìŒì´ ë¶ˆê· í˜•í•©ë‹ˆë‹¤. í”½ì…€ ì¢Œí‘œë¥¼ ì œê±°í•˜ì—¬ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤.")
                            pixel_src_distorted.pop()
                            print(f"   -> í˜„ì¬ ìŒ ê°œìˆ˜: {len(pixel_src_distorted)}")
                        
                else:
                    print("ğŸš¨ í”½ì…€ ì¢Œí‘œ(Enter)ë¥¼ ë¨¼ì € ì €ì¥í•´ì•¼ ë¡œë´‡ ì¢Œí‘œ(Space)ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            elif key == 113 or key == 27:  # 'q' ë˜ëŠ” ESC í‚¤: ì¢…ë£Œ
                break
                
    finally:
        cap.release()
        cv2.destroyAllWindows()
    
    # --- 6. ìµœì¢… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê³„ì‚° ---
    
    if len(pixel_src_distorted) >= 4 and len(pixel_src_distorted) == len(robot_dst_points):
        H_matrix = calculate_homography_matrix_ransac(pixel_src_distorted, robot_dst_points)
        
        if H_matrix is not None:
            print("\nâœ… ì„±ê³µì ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ Hê°€ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("H í–‰ë ¬:")
            print(H_matrix)
            
    else:
        print(f"\nâŒ ì‹¤íŒ¨: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì— í•„ìš”í•œ ìµœì†Œ ì (4ìŒ) ë¯¸ë‹¬ ë˜ëŠ” ë°ì´í„° ë¶ˆì¼ì¹˜.")
        print(f"   -> í”½ì…€ ìŒ: {len(pixel_src_distorted)}, ë¡œë´‡ ìŒ: {len(robot_dst_points)}")


# --- ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ğŸš¨ ì‹œë¦¬ì–¼ í¬íŠ¸ ì´ë¦„ì„ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ë³€ê²½í•˜ì„¸ìš”. (ì˜ˆ: '/dev/ttyACM0', 'COM5', '/dev/ttyUSB0')
    ROBOT_PORT = "/dev/ttyACM0" 
    
    mycobot_controller = MyCobotController(ROBOT_PORT)
    manual_calibration_loop(mycobot_controller)