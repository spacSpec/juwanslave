# ~/final_ws/src/final/final/vision_node.py

import rclpy
from rclpy.node import Node
from my_robot_interfaces.msg import DetectionResult
from sensor_msgs.msg import Image 
from cv_bridge import CvBridge     
import cv2
import numpy as np
import math
from ultralytics import YOLO
import torch

# ===================== [NEW] Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò ÌñâÎ†¨ =====================
# ÏûëÏÑ±ÏûêÎãòÏù¥ Íµ¨ÌïòÏã† 'Î≥¥Î¨ºÏßÄÎèÑ Î≥ÄÌôò Îç∞Ïù¥ÌÑ∞'ÏûÖÎãàÎã§.
# Ïù¥Ï†ú SCALE_X, OFFSET_X Í∞ôÏùÄ Í±¥ ÌïÑÏöî ÏóÜÏäµÎãàÎã§!
CALIB_MATRIX = np.array([
    [0.06216, 0.54554, -63.02774],
    [0.71376, -0.37548, -382.46765],
    [-0.00051, 0.00114, 1.00000]
])

# ===================== ROI ÏÑ§Ï†ï =====================
ROI_X = 100  
ROI_Y = 50   
ROI_W = 440  
ROI_H = 380  

class VisionNode(Node):
    def __init__(self):
        super().__init__('vision_node')
        
        self.result_pub = self.create_publisher(DetectionResult, '/vision/result', 10)
        self.image_pub = self.create_publisher(Image, '/vision/defect_img', 10)
        self.bridge = CvBridge()

        self.device = '0' if torch.cuda.is_available() else 'cpu'
        self.get_logger().info(f'üöÄ Accelerating Inference on Device: {self.device}')
        
        self.model_path = '/home/young/Downloads/best.pt' 
        try:
            self.model = YOLO(self.model_path)
        except Exception as e:
            self.get_logger().error(f'‚ùå Model Load Error: {e}')
            return

        self.cap = cv2.VideoCapture(2)
        if not self.cap.isOpened():
            self.get_logger().error('‚ùå Camera 2 Open Failed. Trying 0...')
            self.cap = cv2.VideoCapture(0)
            
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        self.timer = self.create_timer(0.03, self.process_frame)

    # ================= [ÌïµÏã¨ ÏàòÏ†ï] ÌñâÎ†¨ Î≥ÄÌôò Ìï®Ïàò =================
    def pixel_to_robot(self, u, v):
        """
        ÌîΩÏÖÄ Ï¢åÌëú(u, v) -> Î°úÎ¥á Ï¢åÌëú(x, y) Î≥ÄÌôò (Matrix ÏÇ¨Ïö©)
        """
        # OpenCV Ìï®ÏàòÏóê ÎÑ£Í∏∞ ÏúÑÌï¥ 3Ï∞®Ïõê Î∞∞Ïó¥Î°ú Î≥ÄÌôò
        pixel_point = np.array([[[u, v]]], dtype=np.float32)
        
        # ÌñâÎ†¨ Ïó∞ÏÇ∞ (Ìà¨Ïãú Î≥ÄÌôò) ÏàòÌñâ!
        robot_point = cv2.perspectiveTransform(pixel_point, CALIB_MATRIX)
        
        # Í≤∞Í≥ºÍ∞í: [x, y]
        rx = robot_point[0][0][0]
        ry = robot_point[0][0][1]
        
        # Î°úÍ∑∏Î°ú Î≥ÄÌôòÍ∞í ÌôïÏù∏ (ÎîîÎ≤ÑÍπÖÏö©)
        # self.get_logger().info(f"Trans: ({u},{v}) -> ({rx:.1f}, {ry:.1f})")
        
        return [rx, ry]

    def get_angle_from_roi(self, full_frame, x1, y1, x2, y2):
        """Íπ®ÏßÑ ÌÅêÎ∏åÎèÑ Ïû°ÏïÑÎÇ¥Îäî 'Í≥†Î¨¥Ï§Ñ(Convex Hull)' Í∞ÅÎèÑ Í≥ÑÏÇ∞"""
        h, w = full_frame.shape[:2]
        x1, y1 = max(0, int(x1)), max(0, int(y1))
        x2, y2 = min(w, int(x2)), min(h, int(y2))

        roi = full_frame[y1:y2, x1:x2]
        if roi.size == 0: return 0.0

        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        _, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
        
        cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not cnts: return 0.0
        
        cnt = max(cnts, key=cv2.contourArea)
        hull = cv2.convexHull(cnt)
        rect = cv2.minAreaRect(hull) 
        angle = rect[2]

        if angle < -45: 
            angle = 90 + angle
            
        return angle

    def process_frame(self):
        ret, frame = self.cap.read()
        if not ret: return

        # 1. ROI ÏûêÎ•¥Í∏∞
        roi_img = frame[ROI_Y : ROI_Y + ROI_H, ROI_X : ROI_X + ROI_W]

        # 2. YOLO Ï∂îÎ°†
        results = self.model.predict(roi_img, imgsz=640, conf=0.55, device=self.device, verbose=False)
        
        detection_found = False
        
        if len(results) > 0 and len(results[0].boxes) > 0:
            box = max(results[0].boxes, key=lambda b: float(b.conf[0]))
            
            if self.device == '0':
                local_x1, local_y1, local_x2, local_y2 = box.xyxy[0].cpu().numpy()
            else:
                local_x1, local_y1, local_x2, local_y2 = box.xyxy[0].numpy()
                
            conf = float(box.conf[0])
            
            # [Ï§ëÏöî] Global Ï¢åÌëú Î≥µÏõê (ROI Ïò§ÌîÑÏÖã ÎçîÌïòÍ∏∞)
            # Ïù¥ Ï¢åÌëúÍ∞Ä Ï∫òÎ¶¨Î∏åÎ†àÏù¥ÏÖò ÌñâÎ†¨Ïóê Îì§Ïñ¥Í∞à ÏßÑÏßú ÌîΩÏÖÄ Ï¢åÌëúÏûÖÎãàÎã§.
            global_x1 = local_x1 + ROI_X
            global_y1 = local_y1 + ROI_Y
            global_x2 = local_x2 + ROI_X
            global_y2 = local_y2 + ROI_Y

            cx = int((global_x1 + global_x2) / 2)
            cy = int((global_y1 + global_y2) / 2)

            angle = self.get_angle_from_roi(frame, global_x1, global_y1, global_x2, global_y2)
            
            # [ÏàòÏ†ïÎê®] ÌñâÎ†¨ÏùÑ Ïù¥Ïö©Ìïú Ï¢åÌëú Î≥ÄÌôò Ìò∏Ï∂ú!
            robot_coord = self.pixel_to_robot(cx, cy)
            
            # Î°úÍπÖ: Î≥ÄÌôòÎêú Ï¢åÌëú ÌôïÏù∏
            self.get_logger().info(f"üìç Detect: {quality_str} at Pixel({cx},{cy}) -> Robot({robot_coord[0]:.1f}, {robot_coord[1]:.1f})")

            is_defect = conf < 0.94
            quality_str = "BAD" if is_defect else "GOOD"
            
            msg = DetectionResult()
            msg.is_detected = True
            msg.quality = quality_str
            # Î≥ÄÌôòÎêú Ï¢åÌëú(mm)Î•º Í∑∏ÎåÄÎ°ú Î≥¥ÎÉÖÎãàÎã§.
            msg.center = [float(robot_coord[0]), float(robot_coord[1]), float(angle)]
            self.result_pub.publish(msg)
            detection_found = True
            
            if is_defect:
                try:
                    img_msg = self.bridge.cv2_to_imgmsg(frame, encoding="bgr8")
                    self.image_pub.publish(img_msg)
                except Exception as e: pass
            
            # ÏãúÍ∞ÅÌôî
            color = (0, 0, 255) if is_defect else (0, 255, 0)
            cv2.rectangle(frame, (ROI_X, ROI_Y), (ROI_X + ROI_W, ROI_Y + ROI_H), (255, 0, 0), 2)
            cv2.rectangle(frame, (int(global_x1), int(global_y1)), (int(global_x2), int(global_y2)), color, 2)
            # Î≥ÄÌôòÎêú Ï¢åÌëúÎ•º ÌôîÎ©¥ÏóêÎèÑ ÎùÑÏõåÏ§çÎãàÎã§ (ÌôïÏù∏Ïö©)
            label = f"{quality_str} X:{robot_coord[0]:.0f} Y:{robot_coord[1]:.0f}"
            cv2.putText(frame, label, (int(global_x1), int(global_y1)-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        if not detection_found:
            msg = DetectionResult()
            msg.is_detected = False
            self.result_pub.publish(msg)

        cv2.imshow("Vision Eye", frame)
        cv2.waitKey(1)

    def __del__(self):
        if self.cap.isOpened():
            self.cap.release()

def main(args=None):
    rclpy.init(args=args)
    node = VisionNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()